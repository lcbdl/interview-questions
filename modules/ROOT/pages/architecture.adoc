= Architecture Interview Q&A

== What are the Microservices architecture principles?

Microservices architecture is a design approach that structures an application as a collection of loosely coupled, independently deployable services. Each service corresponds to a specific business function and communicates with other services through well-defined APIs. The principles of microservices architecture are essential for effectively implementing and managing such a system. Here are the key principles:

* Single Responsibility Principle: Each microservice should have a single responsibility, focusing on a specific business capability or function. This makes the service easier to understand, develop, and maintain.   

* Loose Coupling: Services should be as independent as possible. Changes in one service should not require changes in others. This is achieved through well-defined interfaces and communication protocols.
      
* Autonomy: Microservices should be autonomous, meaning they can be developed, deployed, and scaled independently. This independence enhances flexibility and allows teams to choose the best tools and technologies for their specific service.
      
* Continuous Delivery and DevOps: Microservices architecture supports continuous delivery practices, enabling frequent, reliable releases. DevOps practices, including automated testing, integration, and deployment, are essential to manage the complexity of multiple services.
      
* Decentralized Data Management: Instead of a single, centralized database, each microservice manages its own data. This ensures that services are independent and reduces the risk of a single point of failure.
      
* API-First Design: Services communicate through well-defined APIs. An API-first approach ensures that the service interface is designed before implementation, promoting consistency and usability.
      
* Failure Isolation: The architecture should be designed to isolate failures. If one service fails, it should not cause a cascading failure across the system. This can be achieved through techniques like circuit breakers and bulkheads.

** The circuit breaker pattern is implemented on the consumer, to avoid overwhelming a service which may be struggling to handle calls. Example here that uses resilience4j-spring-boot3
** The bulkhead pattern is implemented on the service, to prevent a failure during the handling of a single incoming call impacting the handling of other incoming calls. Example here that uses resilience4j-spring-boot2.
      
* Scalability: Each microservice can be scaled independently based on demand. This allows for more efficient use of resources compared to scaling an entire monolithic application.
      
* Polyglot Persistence and Programming: Microservices can use different technologies and languages best suited for their specific requirements. This flexibility allows teams to choose the most appropriate tool for each job.
      
* Monitoring and Logging: Due to the distributed nature of microservices, comprehensive monitoring and logging are crucial. This helps in diagnosing issues, understanding system behavior, and ensuring reliability.
      
* Event-Driven Architecture: Services often communicate asynchronously through events. This decouples services and allows them to react to changes in other services without direct dependencies.
      
* Security: Each microservice should implement security measures to protect its data and operations. Security must be considered at every level, from API security to data encryption and authentication mechanisms.

== How to implement services to ensure actions are only processed once, even in case of retries or failures?

Implementing idempotent services ensures that the same action is not processed multiple times, even in the face of retries or failures. Idempotence is crucial in distributed systems where network issues or service failures can lead to repeated requests. Here are some strategies and techniques to achieve idempotency:

=== 1. Unique Request Identifiers
Use unique request identifiers (IDs) for each request. This can be a UUID or another unique token generated by the client or the service.
* Client-Side Generation: The client generates a unique ID for each request and sends it along with the request.
* Server-Side Generation: The server generates a unique ID for each request and returns it to the client, which must use it for subsequent retries.

Implementation Steps:

.. When a request is received, check if the unique ID has already been processed.
.. If the ID is found in the database, return the result of the previous processing.
.. If the ID is not found, process the request and store the result along with the ID.

=== 2. Idempotency Keys

An idempotency key is similar to a unique request ID but is typically used for specific operations that need idempotency.

Implementation Steps:
.. Generate an idempotency key for operations that need to be idempotent.
.. Store the key and the result of the operation in a database or cache.
.. On receiving a request with the same idempotency key, return the previously stored result instead of reprocessing the request.

=== 3. Database Constraints

Utilize database constraints to ensure that certain operations are only performed once.

Implementation Steps:
.. Use unique constraints on columns that should not have duplicate entries.
.. Attempt to insert the data. If the insertion fails due to a unique constraint violation, handle the failure gracefully by either returning the existing record or taking appropriate action.

=== 4. Distributed Locks

Use distributed locks to prevent concurrent processing of the same request.

Implementation Steps:

.. Acquire a lock for the specific resource or operation before processing the request.
.. Ensure that only one instance of the service can hold the lock at a time.
.. Process the request and release the lock.

=== 5. Middleware or Interceptors

Implement middleware or interceptors that handle idempotency checks and enforce idempotent behavior before the actual business logic is executed.

Implementation Steps:

.. Intercept incoming requests and extract the unique ID or idempotency key.
.. Perform the idempotency check in the middleware.
.. Pass the request to the business logic only if it hasn’t been processed before.

=== 6. Eventual Consistency

Design the system to handle eventual consistency, ensuring that repeated operations lead to the same result.

Implementation Steps:

.. Design operations to be naturally idempotent, e.g., setting a value (PUT) instead of incrementing (POST).
.. Use compensating transactions to reverse duplicate effects.

Practical Example: Payment Processing Service

Let’s consider implementing idempotency in a payment processing service:

.. Unique Request ID: The client generates a unique request ID for each payment request and sends it to the server.
.. Idempotency Key: The server receives the request and checks if the request ID already exists in the database.
  * If it exists, it returns the result of the previous processing.
  * If it doesn’t exist, it processes the payment and stores the request ID along with the payment result.
.. Database Constraints: The payment record might use a unique constraint on the transaction ID to ensure that duplicate transactions are not recorded.
.. Distributed Lock: A distributed lock (e.g., using Redis) ensures that only one instance of the service processes the payment request at a time.
.. Middleware: Middleware intercepts the request, performs the idempotency check, and only forwards the request to the business logic if it’s not a duplicate.

.Code Example in Pseudocode:
[source python]
----
def process_payment(request):
  request_id = request.headers['Request-ID']

  # Check if request ID already processed
  existing_payment = db.find_payment_by_request_id(request_id)
  if existing_payment:
      return existing_payment.result

  # Acquire distributed lock
  with distributed_lock(request_id):
      # Check again to handle race conditions
      existing_payment = db.find_payment_by_request_id(request_id)
      if existing_payment:
          return existing_payment.result

      # Process payment
      result = payment_gateway.process(request)
      
      # Store result with request ID
      db.save_payment_result(request_id, result)
      
      return result
----

== What are reactive programming paradigms like Project Reactor's Flux?

Reactive programming is a paradigm that focuses on asynchronous data streams and the propagation of changes. It is well-suited for applications that require high performance, scalability, and responsiveness. Project Reactor, a library for building reactive applications on the JVM, is a key player in this space. It provides two primary types: Mono and Flux. Flux is used for handling sequences of 0 to N items, while Mono handles 0 or 1 item.

=== Key Concepts of Reactive Programming

. Asynchronous Data Streams: Reactive programming deals with data as streams that can emit items asynchronously over time.
. Event-Driven: Actions are driven by events (data, user inputs, etc.), and the system reacts to these events.
. Backpressure: A mechanism to handle situations where the producer of data is faster than the consumer, preventing the consumer from being overwhelmed.
. Non-blocking: Reactive systems avoid blocking operations, enhancing performance and scalability.

=== Project Reactor

Project Reactor is an implementation of the Reactive Streams specification, providing a powerful and flexible foundation for reactive applications. It offers a rich set of operators to transform, filter, and combine data streams.

=== Flux: Reactive Sequences of Data

Flux is a reactive type representing a sequence of 0 to N items, potentially infinite. It is a key abstraction in Project Reactor for working with multiple items.

==== Creating a Flux
You can create a Flux using various factory methods:

* Just: Creates a Flux that emits specified items.

[source java]
----
Flux<String> flux = Flux.just("item1", "item2", "item3");
----

* FromIterable: Converts an Iterable into a Flux.

[source java]
----
List<String> items = Arrays.asList("item1", "item2", "item3");
Flux<String> flux = Flux.fromIterable(items);
----

* Range: Generates a range of integers.

[source java]
----
Flux<Integer> rangeFlux = Flux.range(1, 5); // Emits 1, 2, 3, 4, 5
----

==== Transforming a Flux
Flux provides various operators to transform the emitted items:

* Map: Applies a function to each item and emits the result.

[source java]
----
Flux<String> flux = Flux.just("a", "b", "c")
    .map(String::toUpperCase); // Emits "A", "B", "C"
----
==== Filter: Filters items based on a predicate.

[source java]
----
Flux<Integer> evenFlux = Flux.range(1, 10)
    .filter(i -> i % 2 == 0); // Emits 2, 4, 6, 8, 10
----

==== FlatMap: Transforms each item into a Publisher and flattens them.

[source java]
----
Flux<String> flatMappedFlux = Flux.just("flux", "mono")
  .flatMap(s -> Flux.fromArray(s.split(""))); 
  // Emits "f", "l", "u", "x", "m", "o", "n", "o"
----

==== Handling Errors

Reactive programming emphasizes handling errors as part of the stream:

* OnErrorReturn: Provides a fallback value when an error occurs.

[source java]
----
Flux<Integer> flux = Flux.just(1, 2, 0)
  .map(i -> 10 / i)
  .onErrorReturn(-1); // Emits 10, 5, -1
----

* OnErrorResume: Switches to another Flux when an error occurs.

[source java]
----
Flux<Integer> flux = Flux.just(1, 2, 0)
  .map(i -> 10 / i)
  .onErrorResume(e -> Flux.just(100, 200));
  // Emits 10, 5, 100, 200
----

==== Backpressure Handling

Project Reactor provides mechanisms to handle backpressure, ensuring that the consumer is not overwhelmed by the producer:

* Buffer: Collects items into a List and emits them as a single item.

[source java]
----
Flux<List<Integer>> bufferedFlux = Flux.range(1, 10).buffer(3); 
// Emits [1, 2, 3], [4, 5, 6], [7, 8, 9], [10]
----

* Window: Splits the Flux into smaller Flux windows.

[source java]
----
Flux<Flux<Integer>> windowedFlux = Flux.range(1, 10).window(3); 
// Emits Fluxes containing [1, 2, 3], [4, 5, 6], [7, 8, 9], [10]
----

==== Example: Combining Flux and Mono
[source java]
----
Mono<String> mono = Mono.just("Reactive Programming");
Flux<String> combinedFlux = Flux.just("with", "Project Reactor")
    .startWith(mono); 
// Emits "Reactive Programming", "with", "Project Reactor"
----